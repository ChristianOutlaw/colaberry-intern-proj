# Evaluating Results

## What you'll learn
- Understand what accuracy, precision, and recall mean without needing math
- Know how to judge whether an AI model is actually trustworthy
- Recognize why responsible AI requires human oversight, not just good performance numbers

## Key ideas
- A high accuracy score doesn't always mean a model is safe or useful
- Bias in training data produces biased predictions, even when the math looks correct
- Evaluating an AI system means asking about fairness and real-world impact, not just metrics

## Lesson

### What "Accuracy" Really Means — and Why It's Not Enough

When someone says a model is "95% accurate," they mean it predicted correctly 95% of the time on a test set. That sounds strong — but it can be deeply misleading.

**Example:** Suppose 97% of all emails are legitimate and only 3% are spam. A model that classifies *everything* as legitimate would have 97% accuracy — and would catch zero spam. High accuracy, zero usefulness.

This is why teams track multiple metrics:

| Metric | What it measures |
|---|---|
| **Accuracy** | Overall percentage of correct predictions |
| **Precision** | Of all "positive" predictions, how many were actually correct? |
| **Recall** | Of all actual positives in the data, how many did the model find? |
| **F1 Score** | A balance between precision and recall |

Which metric matters most depends on the **cost of each type of mistake**. In medical diagnosis, missing a disease (false negative) can be life-threatening. In spam filtering, the costs are reversed — a missed spam email is less serious than blocking an important one.

### AI Is Only as Fair as Its Data

Every model inherits the patterns — and the biases — of the data it was trained on. When that data reflects historical unfairness, the model will reproduce it.

**Examples:**
- A hiring tool trained on 10 years of data from a company that historically hired mostly men will learn to favor male candidates — even if gender is never an explicit feature.
- A facial recognition system trained predominantly on lighter-skinned faces performs significantly worse on darker-skinned faces.

These aren't bugs in the algorithm. They're biases in the training data that the algorithm faithfully learned and will faithfully repeat at scale.

### Responsible Evaluation Goes Beyond Metrics

Evaluating an AI system means asking:
- Who is harmed when this model is wrong, and how badly?
- Is the training data representative of all the people this model will affect?
- What are the consequences of a false positive compared to a false negative?
- Who is accountable for the outcomes the model produces?

> **"AI is only as fair as the data it learns from" — and only as responsible as the humans who build and deploy it.**

## Common mistakes

**"Ethics and fairness are optional extras — what matters is performance."**

They're not separable. Biased AI systems cause real harm and destroy trust in the organizations that use them. A hiring tool that systematically disadvantages one group isn't just unethical — it's a legal and reputational liability. Responsible design isn't a constraint on performance; it's a requirement for any system that will be used in the real world.

## Quick check

**Q1.** Why does responsible AI matter?

- A) Because biased data can lead to unfair or harmful decisions ✓
- B) Because AI systems can't handle large volumes of data
- C) Because AI should override human ethical judgment
- D) Because fairness principles don't apply to automated systems

**Q2.** A fraud detection model is 99% accurate but only catches 20% of actual fraud cases. Which metric reveals this problem?

- A) Accuracy — which shows the model is performing well
- B) Recall — which reveals the model is missing 80% of real fraud cases ✓
- C) Precision — which only measures false positives
- D) The model is working correctly; there is no problem

## Reflection

**Which area of real-world AI impact concerns you most?**

- Healthcare and social good
- Business and marketing automation
- Creative and generative applications
- Ethics, fairness, and human oversight
